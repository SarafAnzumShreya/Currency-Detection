<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/gh/nihui/ncnn-webassembly-yolov5@ncnn.js"></script>
    <title>Currency Detection</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color:rgb(240, 218, 178);
            color: rgb(136, 91, 91); 
        }
        
        h1 {
            margin: 20px 0;
        }
        
        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 10px;
        }
        
        img {
            border: 4px solid rgb(136, 91, 91);
            border-radius: 8px; 
        }
    </style>
</head>
<body>
    <h1>Currency Detection</h1>
    <div class="video-container">
        <video id="video" width="640" height="480" autoplay></video>
        <canvas id="canvas" width="640" height="480"></canvas>
    </div>

    <!-- Link to NCNN WebAssembly -->
    <script src="https://cdn.jsdelivr.net/npm/ncnn-wasm@1.0.0/ncnn.js"></script>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        let model = null;
        let lastSpokenLabel = "";
        let lastSpokenTime = 0;
        const SPEAK_INTERVAL = 2000; // 2 seconds

        // Initialize NCNN model
        async function loadModel() {
            await ncnn.initWasm();  // Initialize WebAssembly
            
            // Load the model with .param and .bin files
            model = await ncnn.loadModel('best_model.param', 'best_model.bin');
            console.log("NCNN model loaded!");

            // Start detecting after the model is loaded
            setInterval(detectCurrency, 1000);  // Detect every second
        }

        async function detectCurrency() {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

            // Convert image data to tensor for NCNN
            const inputTensor = new ncnn.Tensor(imageData.data, [1, 3, 640, 480]);

            // Run model
            const results = await model.detect(inputTensor);

            // Process results
            processResults(results);
        }

        function processResults(results) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            let detectedLabel = null;
            if (results && results.length > 0) {
                results.forEach((box) => {
                    const [x, y, w, h, conf, classId] = box;
                    if (conf > 0.5) {
                        detectedLabel = `Currency ${classId}`;
                        ctx.strokeStyle = "red";
                        ctx.lineWidth = 2;
                        ctx.strokeRect(x, y, w, h);
                        ctx.fillStyle = "red";
                        ctx.fillText(detectedLabel, x, y - 5);
                    }
                });
            }

            // Speak detected label with a delay to avoid repeating
            if (detectedLabel && shouldSpeak(detectedLabel)) {
                speak(detectedLabel);
            }
        }

        function shouldSpeak(label) {
            const currentTime = Date.now();
            if (label !== lastSpokenLabel || currentTime - lastSpokenTime > SPEAK_INTERVAL) {
                lastSpokenLabel = label;
                lastSpokenTime = currentTime;
                return true;
            }
            return false;
        }

        function speak(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            speechSynthesis.speak(utterance);
            console.log(`Spoken: ${text}`);
        }

        // Start capturing video from the webcam
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        // Initialize everything
        async function init() {
            setupCamera();
            loadModel();  // Load the model after setting up the camera
        }

        init();
    </script>
</body>
</html>
