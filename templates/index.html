<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Currency Detection</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
        }
        h1 {
            margin: 20px 0;
        }
        .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
        }
        img {
            border: 2px solid #333;
        }
    </style>
</head>
<body>
    <h1>Currency Detection</h1>
    <div class="video-container">
        <video id="video" width="640" height="480" autoplay></video>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/onnxjs"></script>
    <script>
        // Setup the webcam
        const videoElement = document.getElementById('video');
        const constraints = {
            video: {
                facingMode: "environment",
                width: { ideal: 640 },
                height: { ideal: 480 }
            }
        };

        // Access the webcam
        navigator.mediaDevices.getUserMedia(constraints)
            .then(stream => {
                videoElement.srcObject = stream;
            })
            .catch(err => {
                console.error('Error accessing webcam: ', err);
            });

        // Load the ONNX model and run inference
        let session;
        const onnxModelPath = "best_model.onnx";  // Your ONNX model path
        onnx.load(onnxModelPath).then(loadedModel => {
            session = loadedModel;
            console.log("ONNX model loaded.");
        }).catch(err => {
            console.error("Failed to load ONNX model: ", err);
        });

        // Run inference on each video frame
        async function runInference() {
            if (session) {
                const frame = videoElement;  // The video element is the webcam frame
                const imageData = getImageDataFromFrame(frame);
                const input = new onnx.Tensor(imageData, 'float32', [1, 3, 640, 640]);

                const output = await session.run([input]);
                const detection = output.values().next().value;  // Assuming your model returns detections

                // Process the detection results
                handleDetection(detection);
            }
        }

        // Extract image data from the video frame (convert to suitable format for ONNX)
        function getImageDataFromFrame(frame) {
            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext("2d");
            canvas.width = frame.videoWidth;
            canvas.height = frame.videoHeight;
            ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
            return ctx.getImageData(0, 0, canvas.width, canvas.height).data;
        }

        // Handle detection and display the result
        function handleDetection(detection) {
            // Handle the detection result (bounding boxes, class names, etc.)
            console.log("Detection result: ", detection);
        }

        // Start the inference loop
        setInterval(runInference, 100);
    </script>
</body>
</html>
